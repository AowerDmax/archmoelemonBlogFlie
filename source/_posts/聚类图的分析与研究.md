---
title: 聚类图的分析与研究
date: 2019-07-21 11:02:31
tags:
- 数据分析
- 绘图
- 聚类图
---

最近在做一些关于分析评论以及情感分析的研究

其中用到了kmeans、 fcm、 dbscan等一些聚类算法

k-means 聚类

聚类算法有很多种，K-Means 是聚类算法中的最常用的一种，算法最大的特点是简单，好理解，运算速度快，但是只能应用于连续型的数据，并且一定要在聚类前需要手工指定要分成几类。

K-Means 聚类算法的大致意思就是“物以类聚，人以群分”：

首先输入 k 的值，即我们指定希望通过聚类得到 k 个分组；
从数据集中随机选取 k 个数据点作为初始大佬（质心）；
对集合中每一个小弟，计算与每一个大佬的距离，离哪个大佬距离近，就跟定哪个大佬。
这时每一个大佬手下都聚集了一票小弟，这时候召开选举大会，每一群选出新的大佬（即通过算法选出新的质心）。
如果新大佬和老大佬之间的距离小于某一个设置的阈值（表示重新计算的质心的位置变化不大，趋于稳定，或者说收敛），可以认为我们进行的聚类已经达到期望的结果，算法终止。

如果新大佬和老大佬距离变化很大，需要迭代3~5步骤。

[原文](https://blog.csdn.net/huangfei711/article/details/78480078)  

[推荐阅读](https://zhuanlan.zhihu.com/p/20432322)

为了使结果更加美观， 可视化， 易于理解， 在这里就推荐几种可视化聚类算法的方法

### matlab

最经典的方法， 网上相关的教程也是最多的， 但也衍生了一个问题， 就算画出来的图是最土的， 没有新鲜感， 在这里我们对这种方法不做介绍， 如果想要了解， 可以通过百度， Google（推荐）搜索得到相关的教程

![matlab图](https://i.loli.net/2019/07/23/5d3650f37057e14555.png)

### R语言

在这里我首推R语言， R语言具有简单易学易上手的特点， 各种扩展包也很丰富， 在使用过程中带来了极大的遍历， 当然主要是ggplot2包太好用了h h

关于R语言的使用， 可以看我的另一篇博文

或者观看B站up主[**阿雷边学边教**](https://space.bilibili.com/41145264)的关于R语言的教程， 讲解非常棒啊h h

其实不需要把R语言学的特别精通， 了解基本的语法以及数据结构后（data.frame数据切片， 一定要好好学， 用处大大的）， 就可以通过Google搜索你想要实现的功能， 然后通过观看官方文档或者[Stack Overflow](https://stackoverflow.com/)来进行更一步的学习

这里推荐两份很棒的学习文档, 都是中文版的， 阅读很方便

1. [基于R语言的科研信息分析与服务](https://bookdown.org/wangminjie/R4IS/)
2. [数据科学中的R语言](https://bookdown.org/wangminjie/R4EDA/#e887b4e8b0a2), 这两份文档都是由一名西南交通大学量子物理专业博编写的

[Quick-R](https://www.statmethods.net/index.html)

通过设置 ellipse.type = "convex"

得到图片![聚点的连线](https://i.loli.net/2019/07/22/5d35d6e24411a86092.png)

```R
setwd("C:/Users/hu1329210652/Desktop/R")
# 清空环境
rm(list=ls())
data("USArrests")
class(USArrests)

site="https://mirrors.tuna.tsinghua.edu.cn/CRAN"
package_list = c("factoextra","cluster")
for(p in package_list){
  if(!suppressWarnings(suppressMessages(require(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))){
    install.packages(p, repos=site)
    suppressWarnings(suppressMessages(library(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))
  }
}
kMeans = read.csv("kMeans.csv")
class(kMeans)
kMeans
row.names(kMeans) <- c("豆瓣", 
                       "韩剧TV", 
                       "知乎", 
                       "易信", 
                       "百度贴吧", 
                       "网易大神", 
                       "小红书", 
                       "QQ", 
                       "旺信", 
                       "堆糖", 
                       "音遇", 
                       "微信", 
                       "QQ空间",
                       "美篇"
                       )
kMeans
kMeans = na.omit(kMeans)
head(kMeans, n=6) 
desc_stats = data.frame( Min=apply(kMeans, 2, min),#minimum
                         Med=apply(kMeans, 2, median),#median
                         Mean=apply(kMeans, 2, mean),#mean
                         SD=apply(kMeans, 2, sd),#Standard deviation
                         Max=apply(kMeans, 2, max)#maximum
)
desc_stats = round(desc_stats, 1)#保留小数点后一位head(desc_stats)
desc_stats
df = scale(kMeans)
res = get_clust_tendency(df, 5, graph = TRUE)
res$hopkins_stat
km.res = kmeans(df, 3, nstart = 25)
fviz_cluster(km.res, 
             kMeans,
             xlab = FALSE, #不显示x坐标
             ylab = FALSE,  #不显示y坐标
             main = "Kmeans",#标题
             ellipse.type = "convex",#设置椭圆的类型
             ellipse.level = 0.95,
             ellipse.alpha = 0.2,
             labelsize = 23)#设置字体的大小

```

通过设置 ellipse.type = "euclid"

![圆形范围](https://i.loli.net/2019/07/22/5d35d7a9b3d3622774.png)

```R
setwd("C:/Users/hu1329210652/Desktop/R")
# 清空环境
rm(list=ls())
data("USArrests")
class(USArrests)

site="https://mirrors.tuna.tsinghua.edu.cn/CRAN"
package_list = c("factoextra","cluster")
for(p in package_list){
  if(!suppressWarnings(suppressMessages(require(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))){
    install.packages(p, repos=site)
    suppressWarnings(suppressMessages(library(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))
  }
}
kMeans = read.csv("kMeans.csv")
class(kMeans)
kMeans
row.names(kMeans) <- c("豆瓣", 
                       "韩剧TV", 
                       "知乎", 
                       "易信", 
                       "百度贴吧", 
                       "网易大神", 
                       "小红书", 
                       "QQ", 
                       "旺信", 
                       "堆糖", 
                       "音遇", 
                       "微信", 
                       "QQ空间",
                       "美篇"
                       )
kMeans
kMeans = na.omit(kMeans)
head(kMeans, n=6) 
desc_stats = data.frame( Min=apply(kMeans, 2, min),#minimum
                         Med=apply(kMeans, 2, median),#median
                         Mean=apply(kMeans, 2, mean),#mean
                         SD=apply(kMeans, 2, sd),#Standard deviation
                         Max=apply(kMeans, 2, max)#maximum
)
desc_stats = round(desc_stats, 1)#保留小数点后一位head(desc_stats)
desc_stats
df = scale(kMeans)
res = get_clust_tendency(df, 5, graph = TRUE)
res$hopkins_stat
km.res = kmeans(df, 3, nstart = 25)
fviz_cluster(km.res, 
             kMeans,
             xlab = FALSE, #不显示x坐标
             ylab = FALSE,  #不显示y坐标
             main = "Kmeans",#标题
             ellipse.type = "euclid",#设置椭圆的类型
             ellipse.level = 0.95,
             ellipse.alpha = 0.2,
             labelsize = 23)#设置字体的大小

```

通过设置ellipse.type = "norm"

![椭圆范围](https://i.loli.net/2019/07/22/5d35d8297e90d28897.png)

```R
setwd("C:/Users/hu1329210652/Desktop/R")
# 清空环境
rm(list=ls())
data("USArrests")
class(USArrests)

site="https://mirrors.tuna.tsinghua.edu.cn/CRAN"
package_list = c("factoextra","cluster")
for(p in package_list){
  if(!suppressWarnings(suppressMessages(require(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))){
    install.packages(p, repos=site)
    suppressWarnings(suppressMessages(library(p, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)))
  }
}
kMeans = read.csv("kMeans.csv")
class(kMeans)
kMeans
row.names(kMeans) <- c("豆瓣", 
                       "韩剧TV", 
                       "知乎", 
                       "易信", 
                       "百度贴吧", 
                       "网易大神", 
                       "小红书", 
                       "QQ", 
                       "旺信", 
                       "堆糖", 
                       "音遇", 
                       "微信", 
                       "QQ空间",
                       "美篇"
                       )
kMeans
kMeans = na.omit(kMeans)
head(kMeans, n=6) 
desc_stats = data.frame( Min=apply(kMeans, 2, min),#minimum
                         Med=apply(kMeans, 2, median),#median
                         Mean=apply(kMeans, 2, mean),#mean
                         SD=apply(kMeans, 2, sd),#Standard deviation
                         Max=apply(kMeans, 2, max)#maximum
)
desc_stats = round(desc_stats, 1)#保留小数点后一位head(desc_stats)
desc_stats
df = scale(kMeans)
res = get_clust_tendency(df, 5, graph = TRUE)
res$hopkins_stat
km.res = kmeans(df, 3, nstart = 25)
fviz_cluster(km.res, 
             kMeans,
             xlab = FALSE, #不显示x坐标
             ylab = FALSE,  #不显示y坐标
             main = "Kmeans",#标题
             ellipse.type = "norm",#设置椭圆的类型
             ellipse.level = 0.95,
             ellipse.alpha = 0.2,
             labelsize = 23)#设置字体的大小

```

### Python

当然还有一种绘图的方法就是调用Python里面的matplotlib库  

![菜鸟教程](http://www.runoob.com/wp-content/uploads/2018/10/color_abbreviation.jpg)